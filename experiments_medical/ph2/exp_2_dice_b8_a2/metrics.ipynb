{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../../../\")\n",
    "\n",
    "import yaml\n",
    "import torch\n",
    "import numpy as np\n",
    "from typing import Dict\n",
    "from architectures.build_architecture import build_architecture\n",
    "from dataloaders.build_dataset import build_dataset\n",
    "from typing import Tuple, Dict\n",
    "from fvcore.nn import FlopCountAnalysis\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import (\n",
    "    jaccard_score,\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "import monai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Config File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(config_path: str) -> Dict:\n",
    "    \"\"\"loads the yaml config file\n",
    "\n",
    "    Args:\n",
    "        config_path (str): _description_\n",
    "\n",
    "    Returns:\n",
    "        Dict: _description_\n",
    "    \"\"\"\n",
    "    with open(config_path, \"r\") as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config\n",
    "\n",
    "\n",
    "config = load_config(\"config.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Dataset and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "# build validation dataset & validataion data loader\n",
    "testset = build_dataset(\n",
    "    dataset_type=config[\"dataset_parameters\"][\"dataset_type\"],\n",
    "    dataset_args=config[\"dataset_parameters\"][\"val_dataset_args\"],\n",
    "    augmentation_args=config[\"test_augmentation_args\"],\n",
    ")\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=1, shuffle=False, num_workers=1\n",
    ")\n",
    "\n",
    "print(len(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_architecture(config=config)\n",
    "checkpoint = torch.load(\"pytorch_model.bin\", map_location=\"cpu\")\n",
    "model.load_state_dict(checkpoint)\n",
    "model = model.to(\"cpu\")\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computational complexity:       1.3 GMac\n",
      "Number of parameters:           3.01 M  \n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "import torch\n",
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "with torch.cuda.device(0):\n",
    "    net = model\n",
    "    macs, params = get_model_complexity_info(\n",
    "        net, (3, 256, 256), as_strings=True, print_per_layer_stat=False, verbose=False\n",
    "    )\n",
    "    print(\"{:<30}  {:<8}\".format(\"Computational complexity: \", macs))\n",
    "    print(\"{:<30}  {:<8}\".format(\"Number of parameters: \", params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::silu encountered 84 time(s)\n",
      "Unsupported operator aten::add encountered 45 time(s)\n",
      "Unsupported operator aten::div encountered 15 time(s)\n",
      "Unsupported operator aten::ceil encountered 6 time(s)\n",
      "Unsupported operator aten::mul encountered 118 time(s)\n",
      "Unsupported operator aten::softmax encountered 21 time(s)\n",
      "Unsupported operator aten::clone encountered 4 time(s)\n",
      "Unsupported operator aten::mul_ encountered 24 time(s)\n",
      "Unsupported operator aten::upsample_bicubic2d encountered 2 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "encoder.encoder.conv_1x1_exp, encoder.encoder.conv_1x1_exp.activation, encoder.encoder.conv_1x1_exp.convolution, encoder.encoder.conv_1x1_exp.normalization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computational complexity:       3.01    \n",
      "Number of parameters:           1.24    \n"
     ]
    }
   ],
   "source": [
    "def flop_count_analysis(\n",
    "    model: torch.nn.Module,\n",
    "    input_dim: Tuple,\n",
    ") -> Dict:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        input_dim (Tuple): shape: (batchsize=1, C, H, W, D(optional))\n",
    "        model (torch.nn.Module): _description_\n",
    "    \"\"\"\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    input_tensor = torch.ones(()).new_empty(\n",
    "        (1, *input_dim),\n",
    "        dtype=next(model.parameters()).dtype,\n",
    "        device=next(model.parameters()).device,\n",
    "    )\n",
    "    flops = FlopCountAnalysis(model, input_tensor)\n",
    "    model_flops = flops.total()\n",
    "    # print(f\"Total trainable parameters: {round(trainable_params * 1e-6, 2)} M\")\n",
    "    # print(f\"MAdds: {round(model_flops * 1e-9, 2)} G\")\n",
    "\n",
    "    out = {\n",
    "        \"params\": round(trainable_params * 1e-6, 2),\n",
    "        \"flops\": round(model_flops * 1e-9, 2),\n",
    "    }\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "inference_result = flop_count_analysis(model, (3, 256, 256))\n",
    "print(\"{:<30}  {:<8}\".format(\"Computational complexity: \", inference_result[\"params\"]))\n",
    "print(\"{:<30}  {:<8}\".format(\"Number of parameters: \", inference_result[\"flops\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate IoU Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8697bc384ea947628f121854eb4d091c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test iou: 0.9229712867991552\n"
     ]
    }
   ],
   "source": [
    "iou = []\n",
    "with torch.no_grad():\n",
    "    for idx, data in tqdm(enumerate(testloader)):\n",
    "        image = data[\"image\"].cuda()\n",
    "        mask = data[\"mask\"].cuda()\n",
    "        out = model.forward(image)\n",
    "        out = torch.sigmoid(out)\n",
    "        out[out < 0.5] = 0\n",
    "        out[out >= 0.5] = 1\n",
    "        mean_iou = jaccard_score(\n",
    "            mask.detach().cpu().numpy().ravel(),\n",
    "            out.detach().cpu().numpy().ravel(),\n",
    "            average=\"binary\",\n",
    "            pos_label=1,\n",
    "        )\n",
    "        iou.append(mean_iou.item())\n",
    "\n",
    "print(f\"test iou: {np.mean(iou)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a451270dd9f04d849a2c32923785143c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.9771324157714844\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "with torch.no_grad():\n",
    "    for idx, data in tqdm(enumerate(testloader)):\n",
    "        image = data[\"image\"].cuda()\n",
    "        mask = data[\"mask\"].cuda()\n",
    "        out = model.forward(image)\n",
    "        out = torch.sigmoid(out)\n",
    "        out[out < 0.5] = 0\n",
    "        out[out >= 0.5] = 1\n",
    "        acc = accuracy_score(\n",
    "            mask.detach().cpu().numpy().ravel(),\n",
    "            out.detach().cpu().numpy().ravel(),\n",
    "        )\n",
    "        accuracy.append(acc.item())\n",
    "\n",
    "print(f\"test accuracy: {np.mean(accuracy)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c465b3238b842bb8ee3f6b37a1b21b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test dice: 0.9569526433944702\n"
     ]
    }
   ],
   "source": [
    "dice = []\n",
    "with torch.no_grad():\n",
    "    for idx, data in tqdm(enumerate(testloader)):\n",
    "        image = data[\"image\"].cuda()\n",
    "        mask = data[\"mask\"].cuda()\n",
    "        out = model.forward(image)\n",
    "        out = torch.sigmoid(out)\n",
    "        out[out < 0.5] = 0\n",
    "        out[out >= 0.5] = 1\n",
    "        mean_dice = monai.metrics.compute_dice(out, mask.unsqueeze(1))\n",
    "        dice.append(mean_dice.item())\n",
    "\n",
    "print(f\"test dice: {np.mean(dice)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "924fdb4171ca424297fcf300084bb352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test specificity: 0.9660395899750096\n"
     ]
    }
   ],
   "source": [
    "specificity = []\n",
    "with torch.no_grad():\n",
    "    for idx, data in tqdm(enumerate(testloader)):\n",
    "        image = data[\"image\"].cuda()\n",
    "        mask = data[\"mask\"].cuda()\n",
    "        out = model.forward(image)\n",
    "        out = torch.sigmoid(out)\n",
    "        out[out < 0.5] = 0\n",
    "        out[out >= 0.5] = 1\n",
    "        confusion = confusion_matrix(\n",
    "            mask.detach().cpu().numpy().ravel(),\n",
    "            out.detach().cpu().numpy().ravel(),\n",
    "        )\n",
    "        if float(confusion[0, 0] + confusion[0, 1]) != 0:\n",
    "            sp = float(confusion[0, 0]) / float(confusion[0, 0] + confusion[0, 1])\n",
    "\n",
    "        specificity.append(sp)\n",
    "\n",
    "print(f\"test specificity: {np.mean(specificity)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7502c6211be24f269ba862fe067fe054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test sensitivity: 0.9604657601219436\n"
     ]
    }
   ],
   "source": [
    "sensitivity = []\n",
    "with torch.no_grad():\n",
    "    for idx, data in tqdm(enumerate(testloader)):\n",
    "        image = data[\"image\"].cuda()\n",
    "        mask = data[\"mask\"].cuda()\n",
    "        out = model.forward(image)\n",
    "        out = torch.sigmoid(out)\n",
    "        out[out < 0.5] = 0\n",
    "        out[out >= 0.5] = 1\n",
    "        confusion = confusion_matrix(\n",
    "            mask.detach().cpu().numpy().ravel(),\n",
    "            out.detach().cpu().numpy().ravel(),\n",
    "        )\n",
    "        if float(confusion[1, 1] + confusion[1, 0]) != 0:\n",
    "            se = float(confusion[1, 1]) / float(confusion[1, 1] + confusion[1, 0])\n",
    "\n",
    "        sensitivity.append(se)\n",
    "\n",
    "print(f\"test sensitivity: {np.mean(sensitivity)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "core",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "db5989e82860003de3542e01be4c3e7827261da67de3613f2a961c26d75654ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
